"""Tests for SIGTERM/cancellation behaviour of SlurmPipesClient.

Unit tests verify that:
- SIGTERM sets the flag but does NOT call scancel
- The exception handler skips scancel when SIGTERM was received
- The exception handler still calls scancel on genuine errors
- Dagster UI "Terminate Run" still calls scancel via the polling loop
"""

import signal
from unittest.mock import MagicMock, patch

import pytest

from dagster_slurm import (
    BashLauncher,
    SlurmResource,
    SSHConnectionResource,
    SlurmQueueConfig,
)
from dagster_slurm.pipes_clients.slurm_pipes_client import SlurmPipesClient


def _make_client() -> SlurmPipesClient:
    """Create a SlurmPipesClient with minimal mock dependencies."""
    ssh = SSHConnectionResource(
        host="localhost",
        port=2223,
        user="testuser",
        password="testpass",
    )
    slurm = SlurmResource(
        ssh=ssh,
        queue=SlurmQueueConfig(
            partition="test",
            time_limit="00:10:00",
            cpus=2,
            mem="1G",
        ),
        remote_base="/tmp/dagster_test",
    )
    return SlurmPipesClient(
        slurm_resource=slurm,
        launcher=BashLauncher(),
    )


# ---------------------------------------------------------------------------
# Unit tests (no Slurm docker needed)
# ---------------------------------------------------------------------------


def test_sigterm_does_not_cancel_job():
    """The signal handler should set _sigterm_received but NOT call scancel."""
    client = _make_client()
    client._current_job_id = 12345
    # Provide a mock SSH pool so _cancel_slurm_job could theoretically work
    client._ssh_pool = MagicMock()

    # Grab the handler that would be registered (we invoke it directly)
    # Replicate the handler logic from the production code:
    with patch.object(client, "_cancel_slurm_job") as mock_cancel:
        # Simulate what the signal handler does
        client._sigterm_received = True
        client.logger = MagicMock()

        # The handler should NOT have triggered scancel
        mock_cancel.assert_not_called()
        assert client._sigterm_received is True


def test_signal_handler_sets_flag():
    """Directly invoke the signal handler function and verify the flag is set."""
    client = _make_client()
    client._current_job_id = 99999
    client._ssh_pool = MagicMock()

    # Build the handler exactly as the production code does, then call it
    def handle_signal(signum, frame):
        client._sigterm_received = True

    assert client._sigterm_received is False
    handle_signal(signal.SIGTERM, None)
    assert client._sigterm_received is True


def test_exception_handler_skips_cancel_on_sigterm():
    """When _sigterm_received is True, the except block should NOT call scancel."""
    client = _make_client()
    client._current_job_id = 12345
    client._ssh_pool = MagicMock()
    client._sigterm_received = True
    client._cancellation_requested = False

    with patch.object(client, "_cancel_slurm_job") as mock_cancel:
        # Simulate the exception handler logic from the `run` method
        if (
            client._current_job_id
            and not client._cancellation_requested
            and not client._sigterm_received
        ):
            client._cancel_slurm_job(client._current_job_id)

        mock_cancel.assert_not_called()


def test_exception_handler_cancels_on_real_error():
    """Without _sigterm_received, the except block SHOULD call scancel."""
    client = _make_client()
    client._current_job_id = 12345
    client._ssh_pool = MagicMock()
    client._sigterm_received = False
    client._cancellation_requested = False

    with patch.object(client, "_cancel_slurm_job") as mock_cancel:
        # Simulate the exception handler logic
        if (
            client._current_job_id
            and not client._cancellation_requested
            and not client._sigterm_received
        ):
            client._cancel_slurm_job(client._current_job_id)

        mock_cancel.assert_called_once_with(12345)


def test_dagster_ui_cancel_still_works():
    """When op_context.is_interrupt_requested is True, scancel IS called."""
    client = _make_client()
    client._current_job_id = 67890
    client._ssh_pool = MagicMock()
    client._sigterm_received = False
    client._cancellation_requested = False

    mock_op_context = MagicMock()
    mock_op_context.is_interrupt_requested = True

    with patch.object(client, "_cancel_slurm_job") as mock_cancel:
        # Simulate the polling loop's Dagster UI cancellation check
        if (
            mock_op_context
            and hasattr(mock_op_context, "is_interrupt_requested")
            and mock_op_context.is_interrupt_requested
        ):
            client._cancellation_requested = True
            client._cancel_slurm_job(client._current_job_id)

        mock_cancel.assert_called_once_with(67890)
        assert client._cancellation_requested is True


def test_sigterm_received_reset_in_finally():
    """The _sigterm_received flag is reset after run() completes."""
    client = _make_client()
    client._sigterm_received = True

    # Simulate the finally block
    client._current_job_id = None
    client._ssh_pool = None
    client._cancellation_requested = False
    client._sigterm_received = False

    assert client._sigterm_received is False


def test_pre_submission_check_blocks_on_sigterm():
    """Pre-submission checks should abort when _sigterm_received is True."""
    client = _make_client()
    client._sigterm_received = True
    client._cancellation_requested = False

    # Simulate the pre-submission guard
    if client._cancellation_requested or client._sigterm_received:
        raised = True
    else:
        raised = False

    assert raised is True


# ---------------------------------------------------------------------------
# Integration tests (need Slurm docker)
# ---------------------------------------------------------------------------


@pytest.mark.needs_slurm_docker
@pytest.mark.slow
def test_terminate_run_cancels_slurm_job(
    slurm_resource_for_testing,
    slurm_cluster_ready,
    temp_dir,
):
    """Submit a long-running job, set is_interrupt_requested, verify CANCELLED."""
    import re
    import time

    from dagster_slurm.helpers.ssh_pool import SSHConnectionPool

    # Create a long-running test payload
    payload = temp_dir / "long_running.py"
    payload.write_text(
        "import time\n"
        "print('started', flush=True)\n"
        "time.sleep(30)\n"
        "print('done', flush=True)\n"
    )

    client = SlurmPipesClient(
        slurm_resource=slurm_resource_for_testing,
        launcher=BashLauncher(),
    )

    ssh_pool = SSHConnectionPool(slurm_resource_for_testing.ssh)
    with ssh_pool:
        remote_base = "/home/submitter/dagster_ci_runs"
        run_dir = f"{remote_base}/test_cancel_{int(time.time())}"
        ssh_pool.run(f"mkdir -p {run_dir}")

        # Upload payload
        remote_payload = f"{run_dir}/long_running.py"
        ssh_pool.upload_file(str(payload), remote_payload)

        # Write a simple job script
        job_script = f"#!/bin/bash\ncd {run_dir}\npython3 {remote_payload}\n"
        script_path = f"{run_dir}/job.sh"
        import tempfile
        from pathlib import Path

        with tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".sh") as f:
            f.write(job_script)
            local_temp = f.name
        ssh_pool.upload_file(local_temp, script_path)
        Path(local_temp).unlink()
        ssh_pool.run(f"chmod +x {script_path}")

        # Submit the job
        output = ssh_pool.run(
            f"sbatch -J test_cancel -D {run_dir} "
            f"-o {run_dir}/slurm-%j.out -e {run_dir}/slurm-%j.err "
            f"-t 00:05:00 -c 1 {script_path}"
        )
        match = re.search(r"Submitted batch job (\d+)", output)
        assert match, f"Could not parse job ID from: {output}"
        job_id = int(match.group(1))

        # Wait a bit for the job to start running
        time.sleep(5)

        # Now cancel it (simulating what the polling loop does on UI cancel)
        client._ssh_pool = ssh_pool
        client._current_job_id = job_id
        client._cancel_slurm_job(job_id)

        # Verify via sacct that the job is CANCELLED
        time.sleep(3)
        sacct_output = ssh_pool.run(
            f"sacct -X -n -j {job_id} -o State 2>/dev/null || true"
        )
        state = sacct_output.strip().split()[0] if sacct_output.strip() else ""
        assert "CANCEL" in state.upper(), f"Expected CANCELLED state, got: {state}"

        # Cleanup
        ssh_pool.run(f"rm -rf {run_dir}")


@pytest.mark.needs_slurm_docker
@pytest.mark.slow
def test_sigterm_preserves_slurm_job(
    slurm_resource_for_testing,
    slurm_cluster_ready,
    temp_dir,
):
    """Submit a job, set _sigterm_received, verify job is NOT cancelled."""
    import re
    import time

    from dagster_slurm.helpers.ssh_pool import SSHConnectionPool

    # Create a short-running test payload (runs for ~15s)
    payload = temp_dir / "short_running.py"
    payload.write_text(
        "import time\n"
        "print('started', flush=True)\n"
        "time.sleep(15)\n"
        "print('done', flush=True)\n"
    )

    client = SlurmPipesClient(
        slurm_resource=slurm_resource_for_testing,
        launcher=BashLauncher(),
    )

    ssh_pool = SSHConnectionPool(slurm_resource_for_testing.ssh)
    with ssh_pool:
        remote_base = "/home/submitter/dagster_ci_runs"
        run_dir = f"{remote_base}/test_sigterm_{int(time.time())}"
        ssh_pool.run(f"mkdir -p {run_dir}")

        # Upload payload
        remote_payload = f"{run_dir}/short_running.py"
        ssh_pool.upload_file(str(payload), remote_payload)

        # Write a simple job script
        job_script = f"#!/bin/bash\ncd {run_dir}\npython3 {remote_payload}\n"
        script_path = f"{run_dir}/job.sh"
        import tempfile
        from pathlib import Path

        with tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".sh") as f:
            f.write(job_script)
            local_temp = f.name
        ssh_pool.upload_file(local_temp, script_path)
        Path(local_temp).unlink()
        ssh_pool.run(f"chmod +x {script_path}")

        # Submit the job
        output = ssh_pool.run(
            f"sbatch -J test_sigterm -D {run_dir} "
            f"-o {run_dir}/slurm-%j.out -e {run_dir}/slurm-%j.err "
            f"-t 00:05:00 -c 1 {script_path}"
        )
        match = re.search(r"Submitted batch job (\d+)", output)
        assert match, f"Could not parse job ID from: {output}"
        job_id = int(match.group(1))

        # Wait a bit for the job to start running
        time.sleep(5)

        # Simulate SIGTERM received â€“ set the flag but do NOT cancel
        client._ssh_pool = ssh_pool
        client._current_job_id = job_id
        client._sigterm_received = True

        # The exception handler should NOT cancel because _sigterm_received is set
        if (
            client._current_job_id
            and not client._cancellation_requested
            and not client._sigterm_received
        ):
            client._cancel_slurm_job(job_id)

        # Verify the job is still running (not cancelled)
        time.sleep(2)
        squeue_output = ssh_pool.run(
            f"squeue -h -j {job_id} -o '%T' 2>/dev/null || true"
        )
        state = squeue_output.strip()
        # Job should be RUNNING or PENDING (not CANCELLED)
        assert state in {"RUNNING", "PENDING", "COMPLETING", "COMPLETED"}, (
            f"Expected job to still be active, got: {state}"
        )

        # Cancel it now so we clean up properly
        ssh_pool.run(f"scancel {job_id} 2>/dev/null || true")
        time.sleep(2)

        # Cleanup
        ssh_pool.run(f"rm -rf {run_dir}")
